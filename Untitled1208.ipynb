{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d70ffa-1af6-47a2-9bd1-87d36f6e1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote:\n",
      " - C:\\Users\\sagni\\Downloads\\GraphGuard\\app.py\n",
      " - C:\\Users\\sagni\\Downloads\\GraphGuard\\index.html\n",
      " - C:\\Users\\sagni\\Downloads\\GraphGuard\\requirements_api.txt\n",
      " - C:\\Users\\sagni\\Downloads\\GraphGuard\\run_api.bat\n",
      "\n",
      "Start the API:\n",
      "  cd \"C:\\Users\\sagni\\Downloads\\GraphGuard\"\n",
      "  pip install -r requirements_api.txt\n",
      "  uvicorn app:app --host 0.0.0.0 --port 8000\n",
      "Open: http://localhost:8000 (redirects to /static/index.html)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# GraphGuard — FastAPI Inference + Explainability pack\n",
    "#   Writes to: C:\\Users\\sagni\\Downloads\\GraphGuard\n",
    "#   Files: app.py, index.html, requirements_api.txt, run_api.bat\n",
    "# Endpoints:\n",
    "#   - GET  /health\n",
    "#   - POST /score   {mode: \"txid\"|\"payload\", ...}\n",
    "#   - POST /explain {txId, k=2, max_nodes=150} -> subgraph + base64 PNG + top features\n",
    "# ============================================================\n",
    "import os\n",
    "BASE = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\"\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "\n",
    "def write(path, content):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "APP_PY = r'''import os, io, csv, json, pickle, base64, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional, List, Dict, Any\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, HTMLResponse\n",
    "from starlette.staticfiles import StaticFiles\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# --------------------------\n",
    "# Paths\n",
    "# --------------------------\n",
    "BASE        = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\"\n",
    "FEATURES_CSV= r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_features.csv\"\n",
    "CLASSES_CSV = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_classes.csv\"\n",
    "EDGES_CSV   = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_edgelist.csv\"\n",
    "\n",
    "PREPROC_PKL = os.path.join(BASE, \"preprocessor.pkl\")\n",
    "H5_PATH     = os.path.join(BASE, \"model.h5\")\n",
    "KERAS_PATH  = os.path.join(BASE, \"model.keras\")  # optional\n",
    "THRESH_PATH = os.path.join(BASE, \"threshold.json\")\n",
    "\n",
    "# --------------------------\n",
    "# Utils\n",
    "# --------------------------\n",
    "def robust_read_csv(path, expected_min_cols=2):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    delims = [\",\",\";\",\"\\t\",\"|\"]\n",
    "    encs   = [\"utf-8\",\"utf-8-sig\",\"cp1252\",\"latin1\"]\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            head = f.read(8192).decode(\"latin1\", errors=\"ignore\")\n",
    "        sniff = csv.Sniffer().sniff(head)\n",
    "        if sniff.delimiter in delims:\n",
    "            delims = [sniff.delimiter] + [d for d in delims if d != sniff.delimiter]\n",
    "    except Exception:\n",
    "        pass\n",
    "    last_err=None\n",
    "    for enc in encs:\n",
    "        for sep in delims:\n",
    "            try:\n",
    "                df = pd.read_csv(path, encoding=enc, sep=sep, engine=\"python\")\n",
    "                if df.shape[1]>=expected_min_cols:\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                last_err=e\n",
    "    raise RuntimeError(f\"Could not parse {path}. Last error: {last_err}\")\n",
    "\n",
    "def numpy_to_base64_png(arr, figsize=(6,4), title=None):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(arr)\n",
    "    if title: plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", dpi=150)\n",
    "    plt.close()\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def fig_to_base64_png():\n",
    "    buf = io.BytesIO()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(buf, format=\"png\", dpi=150)\n",
    "    plt.close()\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# --------------------------\n",
    "# Load artifacts\n",
    "# --------------------------\n",
    "with open(PREPROC_PKL, \"rb\") as f:\n",
    "    preproc = pickle.load(f)\n",
    "\n",
    "feature_cols: List[str] = list(preproc[\"feature_columns\"])\n",
    "scaler = preproc[\"scaler\"]\n",
    "time_col = preproc[\"time_column\"]\n",
    "txid_col = preproc[\"txid_column\"]\n",
    "splits = preproc[\"splits\"]\n",
    "\n",
    "with open(THRESH_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    best_t = float(json.load(f)[\"best_threshold\"])\n",
    "\n",
    "# Model\n",
    "model = None\n",
    "if os.path.exists(KERAS_PATH):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(KERAS_PATH, safe_mode=False)\n",
    "    except Exception:\n",
    "        model=None\n",
    "if model is None and os.path.exists(H5_PATH):\n",
    "    model = tf.keras.models.load_model(H5_PATH)\n",
    "if model is None:\n",
    "    raise RuntimeError(\"Model not found (model.keras / model.h5). Train first.\")\n",
    "\n",
    "# --------------------------\n",
    "# Load dataframes + build graph & lookups\n",
    "# --------------------------\n",
    "df_feat = robust_read_csv(FEATURES_CSV, expected_min_cols=3)\n",
    "df_cls  = robust_read_csv(CLASSES_CSV,  expected_min_cols=2)\n",
    "df_edge = robust_read_csv(EDGES_CSV,    expected_min_cols=2)\n",
    "\n",
    "# Column names\n",
    "feat_cols = list(df_feat.columns)\n",
    "tx_col_feat, time_col_feat = feat_cols[0], feat_cols[1]\n",
    "cls_cols = list(df_cls.columns)\n",
    "tx_col_cls, class_col = cls_cols[0], cls_cols[1]\n",
    "edge_cols = list(df_edge.columns)\n",
    "src_col, dst_col = edge_cols[0], edge_cols[1]\n",
    "\n",
    "# Cast IDs to string\n",
    "df_feat[tx_col_feat] = df_feat[tx_col_feat].astype(str)\n",
    "df_cls[tx_col_cls]   = df_cls[tx_col_cls].astype(str)\n",
    "df_edge[src_col]     = df_edge[src_col].astype(str)\n",
    "df_edge[dst_col]     = df_edge[dst_col].astype(str)\n",
    "\n",
    "# Degrees\n",
    "in_deg  = df_edge.groupby(dst_col).size().rename(\"in_degree\")\n",
    "out_deg = df_edge.groupby(src_col).size().rename(\"out_degree\")\n",
    "deg_df  = pd.concat([in_deg, out_deg], axis=1).fillna(0.0).reset_index()\n",
    "deg_df.rename(columns={deg_df.columns[0]: tx_col_feat}, inplace=True)\n",
    "\n",
    "# Merge features + degrees + labels (labels optional here)\n",
    "df_feat[time_col_feat] = pd.to_numeric(df_feat[time_col_feat], errors=\"coerce\")\n",
    "df = df_feat.merge(deg_df, on=tx_col_feat, how=\"left\")\n",
    "df[[\"in_degree\",\"out_degree\"]] = df[[\"in_degree\",\"out_degree\"]].fillna(0.0)\n",
    "# Optional labels\n",
    "label_map = {\"1\":0,\"2\":1,\"licit\":0,\"illicit\":1}\n",
    "df_cls[class_col] = df_cls[class_col].astype(str).str.lower().str.strip()\n",
    "df_cls[\"label\"] = df_cls[class_col].map(label_map).astype(\"Int64\")\n",
    "df = df.merge(df_cls[[tx_col_cls,\"label\"]], left_on=tx_col_feat, right_on=tx_col_cls, how=\"left\")\n",
    "if tx_col_cls in df.columns and tx_col_cls != tx_col_feat:\n",
    "    df = df.drop(columns=[tx_col_cls])\n",
    "\n",
    "# Keep numeric features\n",
    "for c in feature_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df = df.dropna(subset=[time_col_feat] + feature_cols).reset_index(drop=True)\n",
    "\n",
    "# Build networkx graph for explanations (undirected view is fine for ego)\n",
    "G = nx.from_pandas_edgelist(df_edge, source=src_col, target=dst_col, create_using=nx.Graph())\n",
    "\n",
    "# Index for quick lookup by txId\n",
    "df_indexed = df.set_index(tx_col_feat)\n",
    "\n",
    "# --------------------------\n",
    "# FastAPI app\n",
    "# --------------------------\n",
    "app = FastAPI(title=\"GraphGuard API\", version=\"1.0.0\", description=\"Fraud scoring + k-hop subgraph explanations\")\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
    ")\n",
    "# Serve static (index.html)\n",
    "app.mount(\"/static\", StaticFiles(directory=BASE), name=\"static\")\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def home():\n",
    "    return HTMLResponse('<meta http-equiv=\"refresh\" content=\"0; url=/static/index.html\">')\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"feature_dim\": len(feature_cols),\n",
    "        \"n_nodes\": int(G.number_of_nodes()),\n",
    "        \"n_edges\": int(G.number_of_edges()),\n",
    "        \"threshold\": best_t,\n",
    "        \"time_column\": time_col,\n",
    "        \"txid_column\": txid_col,\n",
    "        \"splits\": {k: len(v) for k,v in splits.items()},\n",
    "    }\n",
    "\n",
    "def _scale_and_predict(x_row: np.ndarray) -> (float, int):\n",
    "    \"\"\"x_row is unscaled features (1, D). Returns prob, pred@best_t\"\"\"\n",
    "    Xs = scaler.transform(x_row)\n",
    "    prob = float(model.predict(Xs, verbose=0).ravel()[0])\n",
    "    pred = 1 if prob >= best_t else 0\n",
    "    return prob, pred\n",
    "\n",
    "def _grad_input_importance(x_scaled: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Gradient x input attribution on scaled features.\"\"\"\n",
    "    x = tf.convert_to_tensor(x_scaled.astype(\"float32\"))\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        p = model(x, training=False)\n",
    "        y = p[:, 0]  # prob of illicit (sigmoid unit)\n",
    "    grads = tape.gradient(y, x).numpy()[0]\n",
    "    # grad * input magnitude\n",
    "    contrib = np.abs(grads * x.numpy()[0])\n",
    "    return contrib\n",
    "\n",
    "def _get_tx_features(txid: str) -> Dict[str, Any]:\n",
    "    if txid not in df_indexed.index:\n",
    "        raise KeyError(f\"txId '{txid}' not found.\")\n",
    "    row = df_indexed.loc[txid]\n",
    "    feat_vals = row[feature_cols].values.reshape(1, -1)\n",
    "    time_step = int(row[time_col])\n",
    "    label = None\n",
    "    if \"label\" in df_indexed.columns and not pd.isna(row.get(\"label\", pd.NA)):\n",
    "        label = int(row[\"label\"])\n",
    "    return {\"x\": feat_vals, \"time\": time_step, \"label\": label}\n",
    "\n",
    "@app.post(\"/score\")\n",
    "async def score(payload: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Two modes:\n",
    "      - {\"mode\":\"txid\", \"txId\":\"...\"}\n",
    "      - {\"mode\":\"payload\", \"features\": {<feature>:value,...}, \"in_degree\":..., \"out_degree\":..., \"timeStep\": <int>}\n",
    "    Returns: prob_illicit, pred_label, (optional) true_label, top_features\n",
    "    \"\"\"\n",
    "    mode = payload.get(\"mode\", \"txid\")\n",
    "    try:\n",
    "        if mode == \"txid\":\n",
    "            txid = str(payload.get(\"txId\", \"\")).strip()\n",
    "            if not txid:\n",
    "                raise ValueError(\"txId required for mode='txid'\")\n",
    "            info = _get_tx_features(txid)\n",
    "            prob, pred = _scale_and_predict(info[\"x\"])\n",
    "            # feature attribution\n",
    "            x_scaled = scaler.transform(info[\"x\"])\n",
    "            contrib = _grad_input_importance(x_scaled)\n",
    "            top_idx = np.argsort(contrib)[::-1][:10]\n",
    "            top_feats = [{\"feature\": feature_cols[i], \"score\": float(contrib[i])} for i in top_idx]\n",
    "            return {\n",
    "                \"txId\": txid,\n",
    "                \"timeStep\": info[\"time\"],\n",
    "                \"prob_illicit\": prob,\n",
    "                \"pred_label\": pred,\n",
    "                \"true_label\": info[\"label\"],\n",
    "                \"threshold\": best_t,\n",
    "                \"top_features\": top_feats\n",
    "            }\n",
    "\n",
    "        elif mode == \"payload\":\n",
    "            fdict = payload.get(\"features\", {})\n",
    "            missing = [c for c in feature_cols if c not in fdict]\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing features: {missing[:10]}...\")\n",
    "            x = np.array([[float(fdict[c]) for c in feature_cols]], dtype=\"float32\")\n",
    "            prob, pred = _scale_and_predict(x)\n",
    "            x_scaled = scaler.transform(x)\n",
    "            contrib = _grad_input_importance(x_scaled)\n",
    "            top_idx = np.argsort(contrib)[::-1][:10]\n",
    "            top_feats = [{\"feature\": feature_cols[i], \"score\": float(contrib[i])} for i in top_idx]\n",
    "            return {\n",
    "                \"prob_illicit\": prob,\n",
    "                \"pred_label\": pred,\n",
    "                \"threshold\": best_t,\n",
    "                \"top_features\": top_feats\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'txid' or 'payload'\")\n",
    "    except KeyError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "def _ego_subgraph_png(txid: str, k: int = 2, max_nodes: int = 150) -> (Dict[str, Any], str):\n",
    "    \"\"\"\n",
    "    Returns (subgraph_json, base64_png) for k-hop ego network around txid.\n",
    "    Limits nodes for readability. Colors center red, neighbors blue.\n",
    "    \"\"\"\n",
    "    if txid not in G:\n",
    "        raise KeyError(f\"txId '{txid}' has no edges in graph.\")\n",
    "    nodes = list(nx.ego_graph(G, txid, radius=k).nodes())\n",
    "    if len(nodes) > max_nodes:\n",
    "        nodes = nodes[:max_nodes]\n",
    "    SG = G.subgraph(nodes).copy()\n",
    "\n",
    "    # JSON\n",
    "    nodes_json = [{\"id\": n} for n in SG.nodes()]\n",
    "    edges_json = [{\"source\": u, \"target\": v} for u, v in SG.edges()]\n",
    "\n",
    "    # PNG rendering\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    pos = nx.spring_layout(SG, seed=42, k=1/np.sqrt(max(len(SG),1)))\n",
    "    node_colors = [\"red\" if n == txid else \"steelblue\" for n in SG.nodes()]\n",
    "    nx.draw_networkx_nodes(SG, pos, node_color=node_colors, node_size=80, alpha=0.9, linewidths=0.3, edgecolors=\"white\")\n",
    "    nx.draw_networkx_edges(SG, pos, alpha=0.4, width=0.8)\n",
    "    # label a few around center\n",
    "    nx.draw_networkx_labels(SG, pos, labels={txid: txid}, font_size=8)\n",
    "    b64 = fig_to_base64_png()\n",
    "    return {\"nodes\": nodes_json, \"edges\": edges_json}, b64\n",
    "\n",
    "@app.post(\"/explain\")\n",
    "async def explain(payload: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Input: {\"txId\": \"...\", \"k\": 2, \"max_nodes\": 150}\n",
    "    Output:\n",
    "      - prob_illicit, pred_label, (optional) true_label\n",
    "      - top_features (grad*input)\n",
    "      - subgraph {nodes, edges}\n",
    "      - subgraph_png_base64\n",
    "    \"\"\"\n",
    "    txid = str(payload.get(\"txId\", \"\")).strip()\n",
    "    k = int(payload.get(\"k\", 2))\n",
    "    max_nodes = int(payload.get(\"max_nodes\", 150))\n",
    "    if not txid:\n",
    "        raise HTTPException(status_code=400, detail=\"txId required\")\n",
    "\n",
    "    try:\n",
    "        info = _get_tx_features(txid)\n",
    "        prob, pred = _scale_and_predict(info[\"x\"])\n",
    "        x_scaled = scaler.transform(info[\"x\"])\n",
    "        contrib = _grad_input_importance(x_scaled)\n",
    "        top_idx = np.argsort(contrib)[::-1][:10]\n",
    "        top_feats = [{\"feature\": feature_cols[i], \"score\": float(contrib[i])} for i in top_idx]\n",
    "\n",
    "        sgj, b64 = _ego_subgraph_png(txid, k=k, max_nodes=max_nodes)\n",
    "        return {\n",
    "            \"txId\": txid,\n",
    "            \"timeStep\": info[\"time\"],\n",
    "            \"prob_illicit\": prob,\n",
    "            \"pred_label\": pred,\n",
    "            \"true_label\": info[\"label\"],\n",
    "            \"threshold\": best_t,\n",
    "            \"top_features\": top_feats,\n",
    "            \"subgraph\": sgj,\n",
    "            \"subgraph_png_base64\": b64\n",
    "        }\n",
    "    except KeyError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "'''\n",
    "\n",
    "INDEX_HTML = r'''<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\"/>\n",
    "  <title>GraphGuard — Fraud Scoring & Explainability</title>\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
    "  <style>\n",
    "    body { font-family: ui-sans-serif, system-ui, Segoe UI, Roboto, Arial; max-width: 1000px; margin: auto; padding: 24px; }\n",
    "    h1 { margin: 0 0 8px; }\n",
    "    .card { border: 1px solid #e5e7eb; border-radius: 12px; padding: 16px; margin: 10px 0; box-shadow: 0 2px 12px rgba(0,0,0,0.04); }\n",
    "    .row { display: flex; gap: 16px; flex-wrap: wrap; }\n",
    "    .col { flex: 1 1 360px; }\n",
    "    input, button { padding: 10px 12px; border-radius: 8px; border: 1px solid #d1d5db; }\n",
    "    button { cursor: pointer; }\n",
    "    button:hover { background: #f3f4f6; }\n",
    "    pre { background: #0b1021; color: #8df; padding: 12px; border-radius: 8px; overflow: auto; }\n",
    "    img { max-width: 100%; border-radius: 8px; }\n",
    "    table { width: 100%; border-collapse: collapse; }\n",
    "    th, td { text-align: left; padding: 6px 8px; border-bottom: 1px solid #eee; }\n",
    "    .pill { display:inline-block; padding: 2px 8px; border-radius: 999px; background:#eef2ff; color:#1f2937; font-size: 12px; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>GraphGuard — Fraud Scoring & Explainability</h1>\n",
    "  <p class=\"pill\">Enter a <b>txId</b> from Elliptic to score and visualize its ego subgraph.</p>\n",
    "\n",
    "  <div class=\"card\">\n",
    "    <div class=\"row\">\n",
    "      <div class=\"col\">\n",
    "        <label>txId</label><br/>\n",
    "        <input id=\"txid\" placeholder=\"e.g. 230425980\" style=\"width:100%\"/>\n",
    "        <div style=\"margin-top:8px;\">\n",
    "          <button id=\"btnScore\">Score</button>\n",
    "          <button id=\"btnExplain\">Explain (k=2)</button>\n",
    "        </div>\n",
    "      </div>\n",
    "      <div class=\"col\">\n",
    "        <div><b>Top Features</b></div>\n",
    "        <table id=\"featTable\"><thead><tr><th>Feature</th><th>Score</th></tr></thead><tbody></tbody></table>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"row\">\n",
    "    <div class=\"col card\">\n",
    "      <h3>Result</h3>\n",
    "      <div id=\"result\"></div>\n",
    "    </div>\n",
    "    <div class=\"col card\">\n",
    "      <h3>Ego Subgraph</h3>\n",
    "      <div id=\"graph\"></div>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <script>\n",
    "    async function postJSON(url, data){\n",
    "      const res = await fetch(url, {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(data)});\n",
    "      const js = await res.json();\n",
    "      if(!res.ok) throw new Error(js.detail || 'Error');\n",
    "      return js;\n",
    "    }\n",
    "    function setResult(js){\n",
    "      document.getElementById('result').innerHTML =\n",
    "        '<p><b>txId:</b> '+(js.txId??'(payload)')+'</p>'+\n",
    "        '<p><b>timeStep:</b> '+(js.timeStep??'')+'</p>'+\n",
    "        '<p><b>prob_illicit:</b> '+js.prob_illicit.toFixed(4)+'</p>'+\n",
    "        '<p><b>pred_label:</b> '+js.pred_label+' ('+(js.pred_label===1?'illicit':'licit')+')</p>'+\n",
    "        (js.true_label!==undefined? '<p><b>true_label:</b> '+js.true_label+'</p>':'')+\n",
    "        '<p><b>threshold:</b> '+js.threshold.toFixed(3)+'</p>';\n",
    "\n",
    "      // features\n",
    "      const tb = document.querySelector('#featTable tbody');\n",
    "      tb.innerHTML = '';\n",
    "      (js.top_features||[]).forEach(r=>{\n",
    "        const tr = document.createElement('tr');\n",
    "        tr.innerHTML = '<td>'+r.feature+'</td><td>'+r.score.toFixed(6)+'</td>';\n",
    "        tb.appendChild(tr);\n",
    "      });\n",
    "    }\n",
    "    async function score(){\n",
    "      const txid = document.getElementById('txid').value.trim();\n",
    "      if(!txid){ alert('Enter txId'); return; }\n",
    "      try{\n",
    "        const js = await postJSON('/score', {mode:'txid', txId: txid});\n",
    "        setResult(js);\n",
    "        document.getElementById('graph').innerHTML = '';\n",
    "      }catch(e){\n",
    "        document.getElementById('result').innerHTML = '<pre>'+e.toString()+'</pre>';\n",
    "      }\n",
    "    }\n",
    "    async function explain(){\n",
    "      const txid = document.getElementById('txid').value.trim();\n",
    "      if(!txid){ alert('Enter txId'); return; }\n",
    "      try{\n",
    "        const js = await postJSON('/explain', {txId: txid, k:2, max_nodes:150});\n",
    "        setResult(js);\n",
    "        if(js.subgraph_png_base64){\n",
    "          document.getElementById('graph').innerHTML = '<img src=\"data:image/png;base64,'+js.subgraph_png_base64+'\"/>';\n",
    "        }else{\n",
    "          document.getElementById('graph').innerHTML = '<pre>'+JSON.stringify(js.subgraph, null, 2)+'</pre>';\n",
    "        }\n",
    "      }catch(e){\n",
    "        document.getElementById('graph').innerHTML = '<pre>'+e.toString()+'</pre>';\n",
    "      }\n",
    "    }\n",
    "    document.getElementById('btnScore').addEventListener('click', score);\n",
    "    document.getElementById('btnExplain').addEventListener('click', explain);\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "REQS = \"\\n\".join([\n",
    "    \"fastapi==0.111.0\",\n",
    "    \"uvicorn[standard]==0.30.1\",\n",
    "    \"pydantic==2.8.2\",\n",
    "    \"numpy>=1.24\",\n",
    "    \"pandas>=2.0.0\",\n",
    "    \"networkx>=3.2\",\n",
    "    \"matplotlib>=3.7.0\",\n",
    "    \"keras>=3.3.0\",\n",
    "    \"tensorflow==2.15.0.post1\",\n",
    "    \"python-multipart>=0.0.9\",\n",
    "]) + \"\\n\"\n",
    "\n",
    "RUN_BAT = r'''@echo off\n",
    "cd /d \"C:\\Users\\sagni\\Downloads\\GraphGuard\"\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements_api.txt\n",
    "uvicorn app:app --host 0.0.0.0 --port 8000\n",
    "'''\n",
    "\n",
    "# write files\n",
    "write(os.path.join(BASE, \"app.py\"), APP_PY)\n",
    "write(os.path.join(BASE, \"index.html\"), INDEX_HTML)\n",
    "write(os.path.join(BASE, \"requirements_api.txt\"), REQS)\n",
    "write(os.path.join(BASE, \"run_api.bat\"), RUN_BAT)\n",
    "\n",
    "print(\"[OK] Wrote:\")\n",
    "print(\" -\", os.path.join(BASE, \"app.py\"))\n",
    "print(\" -\", os.path.join(BASE, \"index.html\"))\n",
    "print(\" -\", os.path.join(BASE, \"requirements_api.txt\"))\n",
    "print(\" -\", os.path.join(BASE, \"run_api.bat\"))\n",
    "\n",
    "print(\"\\nStart the API:\")\n",
    "print(r'  cd \"C:\\Users\\sagni\\Downloads\\GraphGuard\"')\n",
    "print(r'  pip install -r requirements_api.txt')\n",
    "print(r'  uvicorn app:app --host 0.0.0.0 --port 8000')\n",
    "print(\"Open: http://localhost:8000 (redirects to /static/index.html)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c60e1-1c44-48ea-99f9-9f11bdd76781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
