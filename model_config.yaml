project: "GraphGuard \u2014 Elliptic Bitcoin Baseline"
paths:
  features_csv: C:\Users\sagni\Downloads\GraphGuard\archive (1)\elliptic_bitcoin_dataset\elliptic_txs_features.csv
  classes_csv: C:\Users\sagni\Downloads\GraphGuard\archive (1)\elliptic_bitcoin_dataset\elliptic_txs_classes.csv
  edgelist_csv: C:\Users\sagni\Downloads\GraphGuard\archive (1)\elliptic_bitcoin_dataset\elliptic_txs_edgelist.csv
  output_dir: C:\Users\sagni\Downloads\GraphGuard
splits:
  train_steps:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26
  - 27
  - 28
  - 29
  val_steps:
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  test_steps:
  - 40
  - 41
  - 42
  - 43
  - 44
  - 45
  - 46
  - 47
  - 48
  - 49
preprocessing:
  scaler: StandardScaler
  feature_columns:
  - '-0.1714692896288031'
  - '-0.18466755143291433'
  - '-1.2013688016765636'
  - '-0.12196959975910057'
  - '-0.04387454791734898'
  - '-0.11300200928476244'
  - '-0.06158379407303222'
  - '-0.16209679981659642'
  - '-0.16793302645225652'
  - '-0.04970696439403985'
  - '-0.16440217329951'
  - '-0.028741285856664783'
  - '-0.035390552600813516'
  - '-0.042955299258028254'
  - '-0.013281614870058885'
  - '-0.057194633660791555'
  - '-0.16960915015560768'
  - '-0.17115370708833458'
  - '-0.1744725474413385'
  - '-1.3736571773938961'
  - '-1.3714598276027399'
  - '-0.13973120192279553'
  - '-0.1489118870463073'
  - '-0.08014726965335221'
  - '-0.15566142432803598'
  - '-0.010763009512837094'
  - '-0.012107451777478418'
  - '-0.13973300164963834'
  - '-0.14890718609704007'
  - '-0.08014673584659182'
  - '-0.1556613943053229'
  - '-0.0106685610738475'
  - '-0.012005182118417812'
  - '-0.02466883065625352'
  - '-0.031272390486630317'
  - '-0.0230451563960962'
  - '-0.026214655177430907'
  - '0.001427813709709475'
  - '0.0014826437872997916'
  - '-0.22721544644782224'
  - '-0.23936836871437037'
  - '-0.07525553154622772'
  - '-0.23495151756654098'
  - '0.0374680287743863'
  - '0.043444221333941775'
  - '-0.22720332382768585'
  - '-0.24323609254239772'
  - '-0.0978946778840727'
  - '-0.2358964234692872'
  - '0.0365766503766988'
  - '0.04234513480691014'
  - '-0.4140054550165004'
  - '-0.48834041329936734'
  - '-0.23255262057859216'
  - '-0.46755439410398614'
  - '0.048766817854885264'
  - '0.05295606452358398'
  - '-0.03914869407758738'
  - '-0.17289511037923946'
  - '-0.16312596586207964'
  - '-0.16093221729544638'
  - '-1.316342283664295'
  - '-1.3153883882753692'
  - '-0.039143978122140564'
  - '-0.1728840699195216'
  - '-0.16311462864045503'
  - '-0.16092533142876464'
  - '-1.3163333780274464'
  - '-1.315375381290753'
  - '-0.017031675880349647'
  - '-0.030026235277791913'
  - '-0.01764011962990492'
  - '-0.015070900001830685'
  - '-0.14076322246003314'
  - '-0.14033462388732307'
  - '-0.09540268927284089'
  - '-0.26437568843944076'
  - '-0.2505232075535023'
  - '-0.2637032528675492'
  - '1.1335266830129689'
  - '1.1359467007331425'
  - '-0.05901305478547111'
  - '-0.2623679155254754'
  - '-0.25511064604426475'
  - '-0.2591940456978486'
  - '1.1255896087380572'
  - '1.1280380290020882'
  - '-0.29377256255240464'
  - '-0.15973245222462992'
  - '0.034038660711490365'
  - '-0.18381594178200059'
  - '1.135522751490673'
  - '1.135278702458467'
  - '-0.1691595024198962'
  - '-0.20158367565021204'
  - '-0.1168167152870516'
  - '-0.19147194592540379'
  - '-0.014658775691506424'
  - '-0.018848712954381765'
  - '-1.4579532008792007'
  - '-1.494056831372085'
  - '-0.08345878401951694'
  - '-1.4859719767717499'
  - '-0.08879772536984745'
  - '-0.0904370818830761'
  - '-0.16654994856468994'
  - '-0.21653637857822206'
  - '-0.13454647495572797'
  - '-0.19481661068542533'
  - '-0.0031749902209437055'
  - '-0.004094090363360379'
  - '-1.0963356939258175'
  - '-1.2673399140326196'
  - '-0.3499327749819623'
  - '-1.230440801051298'
  - '-0.004357614038573012'
  - '-0.004194370240563965'
  - '-0.11642460389073964'
  - '-0.1766172824237854'
  - '-0.13732327709079195'
  - '-0.15246437130048263'
  - '-0.02605968882058813'
  - '-0.027659714028485525'
  - '-0.09314472701426248'
  - '-0.14370672448675942'
  - '-0.09771859912616487'
  - '-0.12746225048300552'
  - '0.0031432964315106413'
  - '0.0024263098865888125'
  - '-0.1209504155034722'
  - '-0.19914489882884956'
  - '-0.18799267262971858'
  - '-0.21294750674116758'
  - '1.0642045463479908'
  - '1.0637874876466933'
  - '-1.3737824923785267'
  - '-1.3547347717590499'
  - '-0.29797501416794375'
  - '-1.4036981050621322'
  - '1.342003002186918'
  - '1.3407327277377104'
  - '-0.17160149344087147'
  - '-0.4581618412195745'
  - '-0.4235879631572251'
  - '-0.44088282778065335'
  - '-1.0159633735173061'
  - '-1.0162304272806977'
  - '-0.968902874660573'
  - '-0.37571453141267186'
  - '0.759748200156594'
  - '-0.7683292540299814'
  - '1.4881129012284324'
  - '1.487932476808418'
  - '-0.21681436061843226'
  - '-0.6056310578523486'
  - '-0.5621534802884299'
  - '-0.6009988905192808'
  - '1.4613303209554889'
  - '1.4613689382001922'
  - '0.01827940003744589'
  - '-0.0874901561101501'
  - '-0.13115530389558736'
  - '-0.09752359377152515'
  - '-0.12061340670311574'
  - '-0.11979245961251665'
  - in_degree
  - out_degree
  extra_graph_features:
  - in_degree
  - out_degree
model:
  type: MLP
  layers:
  - 256
  - 128
  dropout:
  - 0.3
  - 0.2
  batch_norm: true
  activation: relu
  loss: binary_crossentropy
  optimizer: adam
  learning_rate: 0.001
  metrics:
  - AUC
  - PR_AUC
  - BinaryAccuracy
training:
  epochs: 40
  batch_size: 512
  early_stopping:
    monitor: val_pr_auc
    mode: max
    patience: 5
  class_weight:
    0: 4.594392197840474
    1: 0.5610591237771161
