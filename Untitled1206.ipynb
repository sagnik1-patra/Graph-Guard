{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38e9dbf-f4a0-4976-8187-28ce30406aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded elliptic_txs_features.csv enc='utf-8', sep=',', shape=(203768, 167)\n",
      "[INFO] Loaded elliptic_txs_classes.csv enc='utf-8', sep=',', shape=(203769, 2)\n",
      "[INFO] Loaded elliptic_txs_edgelist.csv enc='utf-8', sep=',', shape=(234355, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model: C:\\Users\\sagni\\Downloads\\GraphGuard\\model.h5\n",
      "[INFO] Test metrics @ best_t=0.260 → ACC=0.9533 | F1=0.9755\n",
      "[INFO] Saved heatmap -> C:\\Users\\sagni\\Downloads\\GraphGuard\\confusion_matrix.png\n",
      "[INFO] Saved accuracy-by-time graph -> C:\\Users\\sagni\\Downloads\\GraphGuard\\accuracy_by_time.png\n",
      "[INFO] Saved classification_report.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# GraphGuard — Accuracy graph + Confusion-matrix heatmap\n",
    "# Outputs:\n",
    "#   - confusion_matrix.png\n",
    "#   - accuracy_curve.png  (if training history available)\n",
    "#     OR accuracy_by_time.png (fallback)\n",
    "# ============================================================\n",
    "import os, csv, json, pickle, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: seaborn for nicer heatmaps\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    USE_SNS = True\n",
    "except Exception:\n",
    "    USE_SNS = False\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (match your project)\n",
    "# -----------------------------\n",
    "FEATURES_PATH = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_features.csv\"\n",
    "CLASSES_PATH  = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_classes.csv\"\n",
    "EDGES_PATH    = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\\archive (1)\\elliptic_bitcoin_dataset\\elliptic_txs_edgelist.csv\"\n",
    "OUTPUT_DIR    = r\"C:\\Users\\sagni\\Downloads\\GraphGuard\"\n",
    "\n",
    "PREPROC_PKL   = os.path.join(OUTPUT_DIR, \"preprocessor.pkl\")\n",
    "H5_PATH       = os.path.join(OUTPUT_DIR, \"model.h5\")\n",
    "KERAS_PATH    = os.path.join(OUTPUT_DIR, \"model.keras\")  # optional\n",
    "THRESH_PATH   = os.path.join(OUTPUT_DIR, \"threshold.json\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Robust CSV reader\n",
    "# -----------------------------\n",
    "def robust_read_csv(path, expected_min_cols=2):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    encodings = [\"utf-8\",\"utf-8-sig\",\"cp1252\",\"latin1\"]\n",
    "    delims    = [\",\",\";\",\"\\t\",\"|\"]\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            head = f.read(8192).decode(\"latin1\", errors=\"ignore\")\n",
    "        sniffed = csv.Sniffer().sniff(head)\n",
    "        if sniffed.delimiter in delims:\n",
    "            delims = [sniffed.delimiter] + [d for d in delims if d != sniffed.delimiter]\n",
    "    except Exception:\n",
    "        pass\n",
    "    last_err = None\n",
    "    for enc in encodings:\n",
    "        for sep in delims:\n",
    "            try:\n",
    "                df = pd.read_csv(path, encoding=enc, sep=sep, engine=\"python\")\n",
    "                if df.shape[1] >= expected_min_cols:\n",
    "                    print(f\"[INFO] Loaded {os.path.basename(path)} enc='{enc}', sep='{sep}', shape={df.shape}\")\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "    raise RuntimeError(f\"Could not parse {path}. Last error: {last_err}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load artifacts\n",
    "# -----------------------------\n",
    "with open(PREPROC_PKL, \"rb\") as f:\n",
    "    preproc = pickle.load(f)\n",
    "\n",
    "feature_cols = preproc[\"feature_columns\"]\n",
    "scaler       = preproc[\"scaler\"]\n",
    "time_col     = preproc[\"time_column\"]\n",
    "txid_col     = preproc[\"txid_column\"]\n",
    "train_steps  = set(preproc[\"splits\"][\"train_steps\"])\n",
    "val_steps    = set(preproc[\"splits\"][\"val_steps\"])\n",
    "test_steps   = set(preproc[\"splits\"][\"test_steps\"])\n",
    "\n",
    "with open(THRESH_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    best_t = float(json.load(f)[\"best_threshold\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Load data, enforce dtypes, merge\n",
    "# -----------------------------\n",
    "df_feat = robust_read_csv(FEATURES_PATH, expected_min_cols=3)\n",
    "df_cls  = robust_read_csv(CLASSES_PATH,  expected_min_cols=2)\n",
    "df_edge = robust_read_csv(EDGES_PATH,    expected_min_cols=2)\n",
    "\n",
    "# Column names\n",
    "feat_cols = list(df_feat.columns)\n",
    "tx_col_feat   = feat_cols[0]\n",
    "time_col_feat = feat_cols[1]\n",
    "# make sure they match what we saved\n",
    "assert tx_col_feat == txid_col, f\"TX ID column mismatch: {tx_col_feat} vs {txid_col}\"\n",
    "assert time_col_feat == time_col, f\"Time column mismatch: {time_col_feat} vs {time_col}\"\n",
    "\n",
    "cls_cols  = list(df_cls.columns)\n",
    "tx_col_cls = cls_cols[0]\n",
    "class_col  = cls_cols[1]\n",
    "\n",
    "edge_cols = list(df_edge.columns)\n",
    "src_col, dst_col = edge_cols[0], edge_cols[1]\n",
    "\n",
    "# Force string TX IDs everywhere (prevents dtype merge errors)\n",
    "df_feat[tx_col_feat] = df_feat[tx_col_feat].astype(str)\n",
    "df_cls[tx_col_cls]   = df_cls[tx_col_cls].astype(str)\n",
    "df_edge[src_col]     = df_edge[src_col].astype(str)\n",
    "df_edge[dst_col]     = df_edge[dst_col].astype(str)\n",
    "\n",
    "# Label mapping; drop unknowns\n",
    "df_cls[class_col] = df_cls[class_col].astype(str).str.lower().str.strip()\n",
    "label_map = {\"1\":0, \"2\":1, \"licit\":0, \"illicit\":1}\n",
    "df_cls[\"label\"] = df_cls[class_col].map(label_map)\n",
    "df_cls = df_cls[~df_cls[\"label\"].isna()].copy()\n",
    "df_cls[\"label\"] = df_cls[\"label\"].astype(int)\n",
    "\n",
    "# Degrees\n",
    "in_deg  = df_edge.groupby(dst_col).size().rename(\"in_degree\")\n",
    "out_deg = df_edge.groupby(src_col).size().rename(\"out_degree\")\n",
    "deg_df  = pd.concat([in_deg, out_deg], axis=1).fillna(0.0).reset_index()\n",
    "deg_df.rename(columns={deg_df.columns[0]: tx_col_feat}, inplace=True)\n",
    "\n",
    "# Merge\n",
    "df_feat[time_col_feat] = pd.to_numeric(df_feat[time_col_feat], errors=\"coerce\")\n",
    "df = df_feat.merge(deg_df, on=tx_col_feat, how=\"left\")\n",
    "df[[\"in_degree\",\"out_degree\"]] = df[[\"in_degree\",\"out_degree\"]].fillna(0.0)\n",
    "df = df.merge(df_cls[[tx_col_cls,\"label\"]], left_on=tx_col_feat, right_on=tx_col_cls, how=\"inner\")\n",
    "if tx_col_cls in df.columns and tx_col_cls != tx_col_feat:\n",
    "    df = df.drop(columns=[tx_col_cls])\n",
    "df = df.dropna(subset=feature_cols + [time_col_feat, \"label\"]).reset_index(drop=True)\n",
    "\n",
    "# Keep only TEST window for evaluation plots\n",
    "df_test = df[df[time_col_feat].isin(test_steps)].copy()\n",
    "X_test  = scaler.transform(df_test[feature_cols].values)\n",
    "y_test  = df_test[\"label\"].astype(int).values\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "model = None\n",
    "if os.path.exists(KERAS_PATH):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(KERAS_PATH, safe_mode=False)\n",
    "        print(\"[INFO] Loaded model:\", KERAS_PATH)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Could not load model.keras:\", e)\n",
    "\n",
    "if model is None and os.path.exists(H5_PATH):\n",
    "    model = tf.keras.models.load_model(H5_PATH)\n",
    "    print(\"[INFO] Loaded model:\", H5_PATH)\n",
    "\n",
    "if model is None:\n",
    "    raise FileNotFoundError(\"No model found (model.keras / model.h5). Train first.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Predict & metrics (test window)\n",
    "# -----------------------------\n",
    "y_prob = model.predict(X_test, batch_size=4096, verbose=0).ravel()\n",
    "y_pred = (y_prob >= best_t).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1  = f1_score(y_test, y_pred, zero_division=0)\n",
    "print(f\"[INFO] Test metrics @ best_t={best_t:.3f} → ACC={acc:.4f} | F1={f1:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion Matrix Heatmap\n",
    "# -----------------------------\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "plt.figure(figsize=(6.5,5.5))\n",
    "if USE_SNS:\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, cmap=\"Blues\",\n",
    "                xticklabels=[\"licit(0)\",\"illicit(1)\"],\n",
    "                yticklabels=[\"licit(0)\",\"illicit(1)\"])\n",
    "else:\n",
    "    plt.imshow(cm, interpolation=\"nearest\"); plt.colorbar()\n",
    "    plt.xticks([0,1], [\"licit(0)\",\"illicit(1)\"], rotation=0)\n",
    "    plt.yticks([0,1], [\"licit(0)\",\"illicit(1)\"])\n",
    "    thresh = cm.max()/2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i,j]),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Test) @ threshold={best_t:.2f}\")\n",
    "plt.tight_layout()\n",
    "cm_path = os.path.join(OUTPUT_DIR, \"confusion_matrix.png\")\n",
    "plt.savefig(cm_path, dpi=150); plt.close()\n",
    "print(f\"[INFO] Saved heatmap -> {cm_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy graph\n",
    "#   A) If training history (hist) exists in memory: plot train/val accuracy\n",
    "#   B) Else: plot accuracy per time step on the TEST window\n",
    "# -----------------------------\n",
    "made_curve = False\n",
    "try:\n",
    "    import builtins\n",
    "    if \"hist\" in builtins.globals() and hasattr(builtins.globals()[\"hist\"], \"history\"):\n",
    "        H = builtins.globals()[\"hist\"].history\n",
    "        if \"accuracy\" in H and \"val_accuracy\" in H and len(H[\"accuracy\"])>0:\n",
    "            epochs = np.arange(1, len(H[\"accuracy\"]) + 1)\n",
    "            plt.figure(figsize=(7.5,5))\n",
    "            plt.plot(epochs, H[\"accuracy\"], label=\"Train Accuracy\")\n",
    "            plt.plot(epochs, H[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "            plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Training/Validation Accuracy\")\n",
    "            plt.grid(True, alpha=0.3); plt.legend()\n",
    "            plt.tight_layout()\n",
    "            acc_curve = os.path.join(OUTPUT_DIR, \"accuracy_curve.png\")\n",
    "            plt.savefig(acc_curve, dpi=150); plt.close()\n",
    "            print(f\"[INFO] Saved accuracy curve -> {acc_curve}\")\n",
    "            made_curve = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Could not read training history:\", e)\n",
    "\n",
    "if not made_curve:\n",
    "    # Fallback: accuracy per time step in TEST window (sorted by time)\n",
    "    test_steps_sorted = sorted(test_steps)\n",
    "    step2acc = []\n",
    "    for s in test_steps_sorted:\n",
    "        mask = (df_test[time_col] == s).values\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        acc_s = accuracy_score(y_test[mask], y_pred[mask])\n",
    "        step2acc.append((s, acc_s))\n",
    "    if len(step2acc) > 0:\n",
    "        steps_arr = np.array([k for k,_ in step2acc])\n",
    "        acc_arr   = np.array([v for _,v in step2acc])\n",
    "        plt.figure(figsize=(8,4.5))\n",
    "        plt.plot(steps_arr, acc_arr, marker=\"o\", linewidth=1)\n",
    "        plt.xlabel(\"Time step\"); plt.ylabel(\"Accuracy\")\n",
    "        plt.ylim(0,1.0); plt.grid(True, alpha=0.3)\n",
    "        plt.title(\"Accuracy by Time (Test window)\")\n",
    "        plt.tight_layout()\n",
    "        acc_time = os.path.join(OUTPUT_DIR, \"accuracy_by_time.png\")\n",
    "        plt.savefig(acc_time, dpi=150); plt.close()\n",
    "        print(f\"[INFO] Saved accuracy-by-time graph -> {acc_time}\")\n",
    "    else:\n",
    "        print(\"[WARN] No test steps found for accuracy-by-time plot.\")\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) classification report text file\n",
    "# -----------------------------\n",
    "rep = classification_report(y_test, y_pred, target_names=[\"licit(0)\",\"illicit(1)\"], digits=4, zero_division=0)\n",
    "with open(os.path.join(OUTPUT_DIR, \"classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rep + \"\\n\")\n",
    "print(\"[INFO] Saved classification_report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bcbbf-0bf5-416d-beb1-4d66c42a52e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
